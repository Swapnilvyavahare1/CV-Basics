{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8596fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3a43a",
   "metadata": {},
   "source": [
    "- Sharpening\n",
    "- Thresholding- Adaptive thresholding is best\n",
    "- Dilation and erosion\n",
    "- Edge detection and Image gradient\n",
    "- Live case of making sketch from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731e9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image sharpening\n",
    "\n",
    "image= cv2.imread('input.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "kernel_sharpening= np.array([[-1,-1,-1],\n",
    "                            [-1,9,-1],\n",
    "                            [-1,-1,-1]   \n",
    "    \n",
    "])\n",
    "sharpened= cv2.filter2D(image, -1, kernel_sharpening)\n",
    "cv2.imshow('Image sharpening', sharpened)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f2afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection amd Image gradient\n",
    "\n",
    "# Sobel\n",
    "# Laplacian\n",
    "# Canny- Best\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('input.jpg')\n",
    "height, width, n = image.shape\n",
    "\n",
    "\n",
    "# Extract Soble Edges\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Sobel X\", sobel_x)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Sobel Y\", sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#sobel_OR = cv2bitwise_or(sobel_x, sobel_y)\n",
    "#cv2.imshow(\"sobel_OR\", sobel_OR)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Laplacian\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow(\"laplacian\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# CANNY Method - best method\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow(\"Canny\", canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e897f85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 1245, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62d0227",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur Live Sketcher\u001b[39m\u001b[38;5;124m\"\u001b[39m, sketch(frame))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m13\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Live case for making sketch from webcam\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "# make sketch function\n",
    "\n",
    "def sketch(image):\n",
    "    # part 1 - convert image to grayscale\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # part 2 - clean up image using Guassian Blur\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray, (5,5), 0)\n",
    "    \n",
    "    # part 3 - Extract Edge - canny\n",
    "    canny_edge = cv2.Canny(img_gray_blur, 10, 70)\n",
    "    \n",
    "    # Part 4 - threshold value\n",
    "    ret, mask = cv2.threshold(canny_edge, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Our Live Sketcher\", sketch(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbebc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "\n",
    "image= cv2.imread('prabhas.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "# Value below 127 is black and above 127 till 255 is white\n",
    "\n",
    "ret, thresh1= cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold type 1', thresh1)\n",
    "\n",
    "ret, thresh2= cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold type 2', thresh2)\n",
    "\n",
    "ret, thresh3= cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('Threshold type 3', thresh3)\n",
    "\n",
    "ret, thresh4= cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('Threshold type 4', thresh4)\n",
    "\n",
    "ret, thresh5= cv2.threshold(image, 127,255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Threshold type 4', thresh5)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da9fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Origin_of_Species.jpg', 0)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('1st Threshold type', thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# it's good practice to blue images as it removes noise\n",
    "\n",
    "image = cv2.GaussianBlur(image, (3,3),0)\n",
    "\n",
    "# Using adaptiveThreshold value\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,3,5 )\n",
    "cv2.imshow(\"AdaptiveThreshold\", thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "_, thresh2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow('2nd THRESH_OTSU type', thresh2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "blur = cv2.GaussianBlur(image, (5,5),0)\n",
    "\n",
    "\n",
    "_, thresh3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow('GaussianBlur Threshold type', thresh3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fc92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilation and erosion\n",
    "\n",
    "# Dilation : adds pixels to the boundaries of objects in an images\n",
    "# Erosion : removes pixels to the boundaries of objects in an images\n",
    "# Opening : Erosion followed by dilation\n",
    "# Closing : Dilation followed by erosion\n",
    "\n",
    "image = cv2.imread('opencv_inv.png',0)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Lets define our kernel size\n",
    "kernel = np.ones((5,5))\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(image, kernel, iterations=1)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# dilation\n",
    "dilation = cv2.dilate(image, kernel, iterations=1)\n",
    "cv2.imshow(\"dilation\", dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"opening\", opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Closing - Good for removing noise\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"closing\", closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53974bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed413a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66d533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f020173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd0fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66abbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dbe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efdf486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a358bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7235e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694508d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a3ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a6517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dd1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8be3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e90d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca594e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9509c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6af9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ea773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b6574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a91b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bb90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14575e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71b541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dcd83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cfdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a5762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
